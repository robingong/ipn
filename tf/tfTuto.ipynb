{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "matrix1 = tf.constant([[3.,3.]])\n",
    "matrix2 = tf.constant([[2.],[2.]]) #2*1 matrix\n",
    "\n",
    "product = tf.matmul(matrix1,matrix2)\n",
    "\n",
    "#session- launch the default graph\n",
    "sess =  tf.Session()\n",
    "\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "#同上\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(product)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu 计算--------------------------\n",
      "[[ 12.]]\n",
      "gpu 计算--------------------------\n",
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "#制定哪个cpu 或 gpu\n",
    "print(\"cpu 计算--------------------------\")\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        matrix1 =  tf.constant([[3.,3.]])\n",
    "        matrix2 = tf.constant([[2.],[2.]])\n",
    "        product = tf.matmul(matrix1,matrix2)\n",
    "        result = sess.run(product)\n",
    "        print(result)\n",
    "\n",
    "print(\"gpu 计算--------------------------\")\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        matrix1 =  tf.constant([[3.,3.]])\n",
    "        matrix2 = tf.constant([[2.],[2.]])\n",
    "        product = tf.matmul(matrix1,matrix2)\n",
    "        result = sess.run(product)\n",
    "        print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2. -1.]\n"
     ]
    }
   ],
   "source": [
    "#交互式 tf session 好像没什么用\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.Variable([1.0,2.0])\n",
    "a = tf.constant([3.0,3.0])\n",
    "x.initializer.run()\n",
    "\n",
    "sub = tf.sub(x,a)\n",
    "print(sub.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\xe5\\xa6\\x82\\xe6\\x9e\\x9c\\xe6\\xb3\\xa8\\xe9\\x87\\x8a\\xe6\\x8e\\x89\\xef\\xbc\\x9a sess.run(init_op)\\nFailedPreconditionError: Attempting to use uninitialized value counter_1\\n\\t [[Node: _send_counter_1_0 = _Send[T=DT_INT32, client_terminated=true, \\n     recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", \\n     send_device=\"/job:localhost/replica:0/task:0/cpu:0\", \\n     send_device_incarnation=3870388527785695788, tensor_name=\"counter_1:0\", \\n     _device=\"/job:localhost/replica:0/task:0/cpu:0\"](counter_1)]]\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#变量  ---这是一个好例子！\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "one = tf.constant(1)\n",
    "\n",
    "new_value = tf.add(state,one)\n",
    "update = tf.assign(state,new_value)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session()  as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(state))\n",
    "        \n",
    "        \n",
    "'''\n",
    "如果注释掉： sess.run(init_op)\n",
    "FailedPreconditionError: Attempting to use uninitialized value counter_1\n",
    "\t [[Node: _send_counter_1_0 = _Send[T=DT_INT32, client_terminated=true, \n",
    "     recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", \n",
    "     send_device=\"/job:localhost/replica:0/task:0/cpu:0\", \n",
    "     send_device_incarnation=3870388527785695788, tensor_name=\"counter_1:0\", \n",
    "     _device=\"/job:localhost/replica:0/task:0/cpu:0\"](counter_1)]]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#结果同上。。。。。。但是内部过程一样吗？\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "one = tf.constant(1)\n",
    "\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "with tf.Session()  as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(state))\n",
    "    for _ in range(3):\n",
    "        state = state + one\n",
    "        print(sess.run(state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "#fetch 取回\n",
    "#如果只是fetch 取回数据的话，是可以不用 sess.Variable()的\n",
    "input1 = tf.constant(3.0)\n",
    "input2 = tf.constant(2.0)\n",
    "input3 = tf.constant(5.0)\n",
    "\n",
    "intermed = tf.add(input2,input3)\n",
    "\n",
    "mul = tf.mul(input1,intermed)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result111 =  sess.run([mul,intermed])\n",
    "    print(result111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#feed 供给\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.mul(input1,input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print( sess.run([output],feed_dict = {input1:[7.],input2:[2.]}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/alex/dev/python/ipythonwork/testData/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/alex/dev/python/ipythonwork/testData/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/alex/dev/python/ipythonwork/testData/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/alex/dev/python/ipythonwork/testData/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-483c89732d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m#让模型训练1000次\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#应该是内置的，随机取\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/alex/try/tensorflow-zh/SOURCE/tutorials/mnist/input_data.pyc\u001b[0m in \u001b[0;36mnext_batch\u001b[0;34m(self, batch_size, fake_data)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_in_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m       \u001b[0;32massert\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_in_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MNIST 机器学习入门\n",
    "'''\n",
    "/media/alex/400E81B50E81A50E/git/tensorflow-zh/SOURCE/tutorials/mnist\n",
    "/Users/alex/try/tensorflow-zh/SOURCE/tutorials/mnist\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1,'/Users/alex/try/tensorflow-zh/SOURCE/tutorials/mnist/')\n",
    "print(sys.path)\n",
    "'''\n",
    "\n",
    "import input_data\n",
    "# 为了用于这个教程,我们使标签数据是\"one-hot vectors\".\n",
    "# 一个 one-hot 向量除了某一位的数字是 1 以外其余各维度数字都是 0.\n",
    "\n",
    "#/Users/alex/dev/python/ipythonwork/MNIST_data/\n",
    "\n",
    "mnist = input_data.read_data_sets(\"/Users/alex/dev/python/ipythonwork/testData/\",one_hot=True)\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "sess = tf.Session()\n",
    "'''\n",
    "下载是成功了，但是不知道下载到哪里去了。。。。\n",
    "Succesfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
    "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
    "......\n",
    "'''\n",
    "'''\n",
    "训练数据集，测试数据集，验证数据集\n",
    "训练和测试数据集 一个数据单元包括：图片xs和对应的标签ys，即 mnist.train.images mnist.train.labels\n",
    "\n",
    "每一张图片包含 28 × 28 像素.我们可以用一个数字数组来表示这张图片\n",
    ",在 MNIST 训练数据集中,mnist.train.images是一个形状为 [55000, 784] 的张量,第一个维度数字用来索引图片,第二个维度数字用来索引每张图片中的像素点.\n",
    "在此张量里的每一个元素,都表示某张图片里的某个像素的强度值,值介于 0 和 1 之间.\n",
    "\n",
    "softmax 模型可以用来给不同的对象分配概率.在后文,我们训练更加复杂的模型时,最后一步也往往需要用softmax 来分配概率.\n",
    "\n",
    "softmax 回归(softmax regression)分两步:首先对输入被分类对象属于某个类的\n",
    "“证据”相加求和,然后将这个“证据”的和转化为概率.\n",
    "\n",
    "我们使用加权的方法来累积计算一张图片是否属于某类的“证据”。如果图片的像\n",
    "素强有力的体现该图不属于某个类,则权重为负数,相反如果这个像素拥有有利的证据\n",
    "支持这张图片属于这个类,那么权值为正.\n",
    "\n",
    "们也需要引入额外的“证据”,可称之为偏置量 (bias)。\n",
    "\n",
    "evidence i =∑ W      X  +  bi\n",
    "                     j    i , j    j \n",
    "i是0-9，j是1-784，evidence i就是：是i（0-9）的证据的大小\n",
    "y = softmax(evidence),是图像表示y（0-9）的概率\n",
    "\n",
    "这里的 softmax 可以看成是一个激励(activation)函数或是链接(link)函数,把我们定\n",
    "义的线性函数的输出转换成我们想要的格式,也就是关于 10 个数字类的概率分布.因\n",
    "此,给定一张图片,它对于每一个数字的吻合度可以被 softmax 函数转换成为一个概率\n",
    "值.softmax 函数可以定义为: softmax(x) = normalize(exp(x)) = exp(Xi) / ∑j exp(Xj)\n",
    " \n",
    " 是更多的时候把 softmax 模型函数定义为第一种形式:把输入值当成幂指数求值,再\n",
    "正则化这些结果值.这个幂运算表示,更大的证据对应更大的假设模型(hypothesis)里\n",
    "面的乘数权重值.反之,拥有更少的证据意味着在假设模型里面拥有更小的乘数系数.\n",
    "假设模型里的权值不可以是 0 值或者负值.Softmax 然后会正则化这些权重值,使它们\n",
    "的总和等于 1,以此构造一个有效的概率分布.\n",
    "\n",
    "p46\n",
    "'''\n",
    "# 建模之旅------------------------\n",
    "#实现回归模型\n",
    "x = tf.placeholder(\"float\",[None,28*28]) #784\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "#训练模型 \n",
    "#找到成本损失函数（交叉熵 cross-entropy）的最小值 \n",
    "y_ = tf.placeholder(\"float\",[None,10]) \n",
    "cross_entropy = - tf.reduce_sum(y_*tf.log(y)) #y_ 会被  batch_ys  替换掉，batch_ys 就是标签，目标分类\n",
    "\n",
    "#用优化算法，不断降低成本\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy) #No gradients provided for any variable\n",
    "\n",
    "#设置好模型后，初始化变量\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "#让模型训练1000次\n",
    "for i in range(1000) :\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)#应该是内置的，随机取\n",
    "    sess.run(train_step,feed_dict={x:batch_xs,y_:batch_ys})\n",
    "\n",
    "#评估模型 tf.argmax(y_,1)代表正确的标签\n",
    "correct_prediction =  tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "#为了确定正确预测项的比例,我们可以把布尔值转换成浮点数,然后取平均值\n",
    "accuracy =  tf.reduce_mean(tf.cast(correct_prediction,\"float\"))\n",
    "#计算所学习到的模型在测试数据集上面的正确率 \n",
    "print( sess.run(accuracy,feed_dict = {x:mnist.test.images,y_:mnist.test.labels}) )  # 0.9154 出现过 0.9208， 有“不稳定性”\n",
    "'''\n",
    "上一行的x数据，是为了通过 y = tf.nn.softmax(tf.matmul(x,W) + b) 计算出y\n",
    "－－》》可以认为前面的训练是得到了W 和 b\n",
    "'''\n",
    "print(W.value())#<tensorflow.python.ops.variables.Variable object at 0x1070a6f90>\n",
    "print(b.value())#<tensorflow.python.ops.variables.Variable object at 0x10ef4b290>\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/alex/dev/python/ipythonwork/testData/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/alex/dev/python/ipythonwork/testData/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/alex/dev/python/ipythonwork/testData/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/alex/dev/python/ipythonwork/testData/t10k-labels-idx1-ubyte.gz\n",
      "0.1135\n"
     ]
    }
   ],
   "source": [
    "#Deep MNIST for Experts || 深入 MNIST\n",
    "import input_data\n",
    "#/Users/alex/dev/python/ipythonwork/MNIST_data\n",
    "#/Users/alex/dev/python/ipythonwork/testData\n",
    "mnist = input_data.read_data_sets(\"/Users/alex/dev/python/ipythonwork/testData\",one_hot=True)\n",
    "\n",
    "#开始 TensorFlow 交互会话\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#计算图\n",
    "x = tf.placeholder(\"float\",shape=[None,784])\n",
    "y_ = tf.placeholder(\"float\",shape=[None,10])\n",
    "\n",
    "#变量\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "#预测分类和损失函数\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "cross_entropy = - tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# Train the Model | 训练模型\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n",
    "#Evaluate the Model | 评估模型\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\"))\n",
    "\n",
    "print accuracy.eval(feed_dict={x: mnist.test.images , y_: mnist.test.labels}) #0.9092\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step   0,  training   accuracy   0.1\n",
      "step   200,  training   accuracy   0.84\n",
      "step   400,  training   accuracy   0.88\n",
      "step   600,  training   accuracy   0.96\n",
      "step   800,  training   accuracy   0.98\n",
      "step   1000,  training   accuracy   0.94\n",
      "step   1200,  training   accuracy   0.98\n",
      "step   1400,  training   accuracy   0.96\n",
      "step   1600,  training   accuracy   0.96\n",
      "step   1800,  training   accuracy   0.98\n",
      "step   2000,  training   accuracy   1\n",
      "step   2200,  training   accuracy   1\n",
      "step   2400,  training   accuracy   0.98\n",
      "step   2600,  training   accuracy   0.96\n",
      "step   2800,  training   accuracy   0.98\n",
      "step   3000,  training   accuracy   0.96\n",
      "step   3200,  training   accuracy   1\n",
      "step   3400,  training   accuracy   1\n",
      "step   3600,  training   accuracy   1\n",
      "step   3800,  training   accuracy   0.96\n",
      "step   4000,  training   accuracy   0.98\n",
      "step   4200,  training   accuracy   1\n",
      "step   4400,  training   accuracy   0.98\n",
      "step   4600,  training   accuracy   0.98\n",
      "step   4800,  training   accuracy   1\n",
      "step   5000,  training   accuracy   0.98\n",
      "step   5200,  training   accuracy   0.98\n",
      "step   5400,  training   accuracy   1\n",
      "step   5600,  training   accuracy   1\n",
      "step   5800,  training   accuracy   1\n",
      "step   6000,  training   accuracy   0.96\n",
      "step   6200,  training   accuracy   0.98\n",
      "step   6400,  training   accuracy   1\n",
      "step   6600,  training   accuracy   1\n",
      "step   6800,  training   accuracy   1\n",
      "step   7000,  training   accuracy   1\n",
      "step   7200,  training   accuracy   1\n",
      "step   7400,  training   accuracy   1\n",
      "step   7600,  training   accuracy   1\n",
      "step   7800,  training   accuracy   0.98\n",
      "step   8000,  training   accuracy   0.98\n",
      "step   8200,  training   accuracy   0.98\n",
      "step   8400,  training   accuracy   1\n",
      "step   8600,  training   accuracy   1\n",
      "step   8800,  training   accuracy   1\n",
      "step   9000,  training   accuracy   1\n",
      "step   9200,  training   accuracy   1\n",
      "step   9400,  training   accuracy   1\n",
      "step   9600,  training   accuracy   1\n",
      "step   9800,  training   accuracy   1\n",
      "step   10000,  training   accuracy   1\n",
      "step   10200,  training   accuracy   1\n",
      "step   10400,  training   accuracy   0.98\n",
      "step   10600,  training   accuracy   1\n",
      "step   10800,  training   accuracy   1\n",
      "step   11000,  training   accuracy   1\n",
      "step   11200,  training   accuracy   1\n",
      "step   11400,  training   accuracy   1\n",
      "step   11600,  training   accuracy   1\n",
      "step   11800,  training   accuracy   1\n",
      "step   12000,  training   accuracy   1\n",
      "step   12200,  training   accuracy   1\n",
      "step   12400,  training   accuracy   1\n",
      "step   12600,  training   accuracy   1\n",
      "step   12800,  training   accuracy   1\n",
      "step   13000,  training   accuracy   0.98\n",
      "step   13200,  training   accuracy   1\n",
      "step   13400,  training   accuracy   1\n",
      "step   13600,  training   accuracy   1\n",
      "step   13800,  training   accuracy   1\n",
      "step   14000,  training   accuracy   0.98\n",
      "step   14200,  training   accuracy   1\n",
      "step   14400,  training   accuracy   1\n",
      "step   14600,  training   accuracy   1\n",
      "step   14800,  training   accuracy   0.98\n",
      "step   15000,  training   accuracy   1\n",
      "step   15200,  training   accuracy   1\n",
      "step   15400,  training   accuracy   0.98\n",
      "step   15600,  training   accuracy   1\n",
      "step   15800,  training   accuracy   1\n",
      "step   16000,  training   accuracy   1\n",
      "step   16200,  training   accuracy   1\n",
      "step   16400,  training   accuracy   1\n",
      "step   16600,  training   accuracy   1\n",
      "step   16800,  training   accuracy   1\n",
      "step   17000,  training   accuracy   1\n",
      "step   17200,  training   accuracy   1\n",
      "step   17400,  training   accuracy   1\n",
      "step   17600,  training   accuracy   1\n",
      "step   17800,  training   accuracy   1\n",
      "step   18000,  training   accuracy   1\n",
      "step   18200,  training   accuracy   1\n",
      "step   18400,  training   accuracy   0.98\n",
      "step   18600,  training   accuracy   1\n",
      "step   18800,  training   accuracy   1\n",
      "step   19000,  training   accuracy   1\n",
      "step   19200,  training   accuracy   1\n",
      "step   19400,  training   accuracy   0.96\n",
      "step   19600,  training   accuracy   1\n",
      "step   19800,  training   accuracy   1\n",
      "test  accuracy 0.9917\n"
     ]
    }
   ],
   "source": [
    "#! Build a Multilayer Convolutional Network | 构建多层卷积网络模型\n",
    "\n",
    "#Weight Initialization | 权重初始化\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#Convolution and Pooling | 卷积和池化\n",
    "def conv2d(x, W):\n",
    "     return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2,1], padding='SAME')\n",
    "\n",
    "#First Convolutional Layer | 第一层卷积\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [ -1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image , W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#Second Convolutional Layer | 第二层卷积\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1 , W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#Densely Connected Layer | 密集连接层\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2 , [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat , W_fc1) + b_fc1)\n",
    " \n",
    "#Dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#Readout Layer | 输出层\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop , W_fc2) + b_fc2)\n",
    "\n",
    "#Train and Evaluate the Model | 训练和评估模型\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv ,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , \"float\"))\n",
    "\n",
    "sess =  tf.InteractiveSession()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%200 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print \"step   %d,  training   accuracy   %g\"%(i, train_accuracy)\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob:0.5})\n",
    "\n",
    "print \"test  accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images , y_: mnist.test.labels , keep_prob: 1.0})\n",
    "#test  accuracy 0.9915\n",
    "#GPU 处于 85% 以上\n",
    " \n",
    "sess.close()\n",
    "#test  accuracy 0.9917 cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '~/try/tensorflow-zh/SOURCE/tutorials/mnist/', '/Applications/anaconda/lib/python2.7/site-packages/Cola-0.1.0b0-py2.7.egg', '/Applications/anaconda/lib/python27.zip', '/Applications/anaconda/lib/python2.7', '/Applications/anaconda/lib/python2.7/plat-darwin', '/Applications/anaconda/lib/python2.7/plat-mac', '/Applications/anaconda/lib/python2.7/plat-mac/lib-scriptpackages', '/Applications/anaconda/lib/python2.7/lib-tk', '/Applications/anaconda/lib/python2.7/lib-old', '/Applications/anaconda/lib/python2.7/lib-dynload', '/Users/alex/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/site-packages', '/usr/local/Cellar/numpy/1.10.4/libexec/nose/lib/python2.7/site-packages', '/Applications/anaconda/lib/python2.7/site-packages/Sphinx-1.3.5-py2.7.egg', '/Applications/anaconda/lib/python2.7/site-packages', '/Applications/anaconda/lib/python2.7/site-packages/aeosa', '/Applications/anaconda/lib/python2.7/site-packages/setuptools-20.3-py2.7.egg', '/Applications/anaconda/lib/python2.7/site-packages/IPython/extensions', '/Users/alex/.ipython']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
